{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis and Reporting:**\n",
    "\n",
    "17. **Classification Reports and Confusion Matrices:** These functions generate reports summarizing model performance metrics for classification tasks.\n",
    "18. **Regression Evaluation Metrics:** These functions calculate and report metrics for regression tasks.\n",
    "19. **Feature Importance Analysis:** This function analyzes and reports feature importance scores to understand which features contribute most to the model's predictions.\n",
    "20. **Model Persistence:** This function saves your trained model for future use or deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model ensembling techniques (boosting and bagging) next??**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with with trained_model returned, please use the same interactive, automated, and nontechnical-user-friendly logic to write a model evaluation function/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Classification Reports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def generate_classification_report(trained_model, val_data):\n",
    "  \"\"\"\n",
    "  Guides the user through generating a classification report for the trained model on the validation data.\n",
    "\n",
    "  Args:\n",
    "      trained_model (object): The trained classification model.\n",
    "      val_data (pandas.DataFrame): The DataFrame containing the validation data (features and target).\n",
    "  \"\"\"\n",
    "\n",
    "  print(\"\\n** Generating a classification report...**\")\n",
    "  print(\"This report provides a detailed breakdown of the model's performance for each class in the classification task.\")\n",
    "\n",
    "  # Make predictions on the validation data\n",
    "  predictions = trained_model.predict(val_data.drop(\"target\", axis=1))\n",
    "\n",
    "  # Confirmation for Report Generation\n",
    "  print(\"\\n** Would you like to generate a classification report? (y/n) **\")\n",
    "  while True:\n",
    "    choice = input().lower()\n",
    "    if choice in [\"y\", \"n\"]:\n",
    "      break\n",
    "    else:\n",
    "      print(\"Invalid choice. Please choose 'y' or 'n'.\")\n",
    "\n",
    "  if choice == \"y\":\n",
    "    # Generate and display the report\n",
    "    report = classification_report(val_data[\"target\"], predictions, output_dict=True)\n",
    "    print(\"\\n** Classification Report:**\")\n",
    "    for class_name, metrics in report.items():\n",
    "      print(f\"\\n** Class: {class_name} **\")\n",
    "      for metric_name, value in metrics.items():\n",
    "        print(f\"  - {metric_name}: {value:.4f}\")  # Format metric values\n",
    "\n",
    "  else:\n",
    "    print(\"\\n** Skipping classification report generation.**\")\n",
    "\n",
    "  return report  # Optional: Return the report dictionary (if generated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Function Purpose:** This function takes the trained model (`trained_model`) and validation data (`val_data`) as input, guiding the user through generating a classification report.\n",
    "2. **Explanation of Report:** It informs the user about the report's purpose of providing detailed class-wise performance metrics.\n",
    "3. **Making Predictions:** Similar to the `evaluate_model` function, it makes predictions on the validation data.\n",
    "4. **Confirmation for Report Generation:** It asks the user for confirmation (y/n) to generate the report, maintaining interactivity.\n",
    "5. **Generating and Displaying the Report (if chosen):**\n",
    "   - If the user confirms, it uses `classification_report` with `output_dict=True` to create a dictionary containing class-wise metrics.\n",
    "   - It iterates through the report dictionary and displays class names, metric names, and their values in a user-friendly format.\n",
    "6. **Skipping Report Generation (if not chosen):** Informs the user that report generation is skipped.\n",
    "7. **Optional Return Value:** The function can optionally return the generated report dictionary (if created) for further analysis or visualization using libraries like `pandas`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Confusion Matrices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib as plt\n",
    "\n",
    "def visualize_confusion_matrix(trained_model, val_data):\n",
    "  \"\"\"\n",
    "  Guides the user through generating and visualizing a confusion matrix for the trained model on the validation data.\n",
    "\n",
    "  Args:\n",
    "      trained_model (object): The trained classification model.\n",
    "      val_data (pandas.DataFrame): The DataFrame containing the validation data (features and target).\n",
    "  \"\"\"\n",
    "\n",
    "  print(\"\\n** Visualizing the confusion matrix...**\")\n",
    "  print(\"This helps us understand how often the model correctly classified each class and where it made mistakes.\")\n",
    "\n",
    "  # Make predictions on the validation data\n",
    "  predictions = trained_model.predict(val_data.drop(\"target\", axis=1))\n",
    "\n",
    "  # Confirmation for Confusion Matrix Visualization\n",
    "  print(\"\\n** Would you like to visualize the confusion matrix? (y/n) **\")\n",
    "  while True:\n",
    "    choice = input().lower()\n",
    "    if choice in [\"y\", \"n\"]:\n",
    "      break\n",
    "    else:\n",
    "      print(\"Invalid choice. Please choose 'y' or 'n'.\")\n",
    "\n",
    "  if choice == \"y\":\n",
    "    # Generate and display the confusion matrix (using library like seaborn)\n",
    "    try:\n",
    "      import seaborn as sns  # Import seaborn for visualization (optional)\n",
    "      sns.heatmap(confusion_matrix(val_data[\"target\"], predictions), annot=True, fmt=\"d\")  # Annotate and format\n",
    "      plt.show()  # Display the heatmap\n",
    "    except ModuleNotFoundError:\n",
    "      print(\"\\n** seaborn library not found for visualization. Confusion matrix values:\")\n",
    "      print(confusion_matrix(val_data[\"target\"], predictions))\n",
    "    except Exception as e:\n",
    "      print(f\"\\n** Error occurred while visualizing the confusion matrix: {e}\")\n",
    "    else:\n",
    "      print(\"\\n** Confusion matrix visualized (using seaborn if available).**\")\n",
    "\n",
    "  else:\n",
    "    print(\"\\n** Skipping confusion matrix visualization.**\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **Function Purpose:** This function takes the trained model (`trained_model`) and validation data (`val_data`) as input, guiding the user through generating and visualizing a confusion matrix.\n",
    "2. **Explanation of Confusion Matrix:** It informs the user about the purpose of the confusion matrix in understanding classification performance.\n",
    "3. **Making Predictions:** Similar to previous functions, it makes predictions on the validation data.\n",
    "4. **Confirmation for Visualization:** It asks for user confirmation (y/n) to visualize the confusion matrix.\n",
    "5. **Generating and Displaying the Confusion Matrix (if chosen):**\n",
    "   - If the user confirms, it attempts to use `seaborn` for a visual heatmap with annotations and formatting.\n",
    "   - If `seaborn` is not found, it displays the raw confusion matrix values as a table.\n",
    "   - In case of any errors, it informs the user and skips visualization.\n",
    "   - If successful, it confirms the visualization (using `seaborn` if available).\n",
    "6. **Skipping Visualization (if not chosen):** Informs the user that visualization is skipped.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Learning Curves**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curves(trained_model, train_data, val_data):\n",
    "  \"\"\"\n",
    "  Guides the user through plotting learning curves for the trained model.\n",
    "\n",
    "  Args:\n",
    "      trained_model (object): The trained classification or regression model.\n",
    "      train_data (pandas.DataFrame): The DataFrame containing the training data (features and target).\n",
    "      val_data (pandas.DataFrame): The DataFrame containing the validation data (features and target).\n",
    "  \"\"\"\n",
    "\n",
    "  print(\"\\n** Visualizing learning curves...**\")\n",
    "  print(\"Learning curves show how the model's performance (training and validation scores) changes with the amount of training data.\")\n",
    "\n",
    "  # Confirmation for Learning Curve Plot\n",
    "  print(\"\\n** Would you like to visualize learning curves? (y/n) **\")\n",
    "  while True:\n",
    "    choice = input().lower()\n",
    "    if choice in [\"y\", \"n\"]:\n",
    "      break\n",
    "    else:\n",
    "      print(\"Invalid choice. Please choose 'y' or 'n'.\")\n",
    "\n",
    "  if choice == \"y\":\n",
    "    # Import libraries for plotting (replace with your preferred library)\n",
    "    try:\n",
    "      import matplotlib.pyplot as plt\n",
    "      from sklearn.model_selection import learning_curve\n",
    "    except ModuleNotFoundError as e:\n",
    "      print(f\"\\n** Required libraries (matplotlib, sklearn) not found for plotting. Skipping learning curves.**\")\n",
    "      return\n",
    "\n",
    "    # Extract features and target\n",
    "    X_train = train_data.drop(\"target\", axis=1)\n",
    "    y_train = train_data[\"target\"]\n",
    "    X_val = val_data.drop(\"target\", axis=1)\n",
    "    y_val = val_data[\"target\"]\n",
    "\n",
    "    # Define model class (assuming you have the class definition)\n",
    "    model_class = trained_model.__class__  # Get the class of the trained model\n",
    "\n",
    "    # Define train_sizes for the curve\n",
    "    train_sizes, train_scores, val_scores = learning_curve(model_class(), X_train, y_train, cv=5, scoring=\"accuracy\")  # Replace 'accuracy' with relevant metric\n",
    "\n",
    "    # Plot the learning curve\n",
    "    plt.figure()\n",
    "    plt.plot(train_sizes, train_scores.mean(axis=1), label=\"Training Score\")\n",
    "    plt.plot(train_sizes, val_scores.mean(axis=1), label=\"Validation Score\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xlabel(\"Training Set Size\")\n",
    "    plt.title(\"Learning Curves\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "  else:\n",
    "    print(\"\\n** Skipping learning curves visualization.**\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation of the Function:**\n",
    "\n",
    "1. **Function Purpose:** This function takes the trained model (`trained_model`), training data (`train_data`), and validation data (`val_data`) as input, guiding the user through plotting learning curves.\n",
    "2. **Explanation of Learning Curves:** It informs the user about the purpose of learning curves in understanding how model performance changes with training data size.\n",
    "3. **Confirmation for Plotting:** It asks for user confirmation (y/n) to visualize the learning curves.\n",
    "4. **Learning Curve Plotting (if chosen):**\n",
    "   - It checks for necessary libraries (`matplotlib`, `sklearn`) and informs the user if they're missing.\n",
    "   - If libraries are available, it extracts features and target from both training and validation data.\n",
    "   - It retrieves the class of the trained model for learning curve generation.\n",
    "   - It defines training data sizes (`train_sizes`) and uses `learning_curve` from `sklearn.model_selection` to calculate training and validation scores across different training set sizes.\n",
    "   - The function plots the learning curve using `matplotlib`, displaying both training and validation scores.\n",
    "5. **Skipping Plotting (if not chosen):** Informs the user that learning curve plotting is skipped.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ROC Curves (for Classification)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curve(trained_model, val_data):\n",
    "  \"\"\"\n",
    "  Guides the user through plotting ROC curves for the trained classification model.\n",
    "\n",
    "  Args:\n",
    "      trained_model (object): The trained classification model.\n",
    "      val_data (pandas.DataFrame): The DataFrame containing the validation data (features and target).\n",
    "  \"\"\"\n",
    "\n",
    "  print(\"\\n** Visualizing ROC curves (for classification models only)...**\")\n",
    "  print(\"ROC curves show the trade-off between true positive rates (TPR) and false positive rates (FPR) at different classification thresholds.\")\n",
    "\n",
    "  # Check if the model is a classification model\n",
    "  if not hasattr(trained_model, \"predict_proba\"):\n",
    "    return\n",
    "\n",
    "  # Confirmation for ROC Curve Plot\n",
    "  print(\"\\n** Would you like to visualize ROC curves? (y/n) **\")\n",
    "  while True:\n",
    "    choice = input().lower()\n",
    "    if choice in [\"y\", \"n\"]:\n",
    "      break\n",
    "    else:\n",
    "      print(\"Invalid choice. Please choose 'y' or 'n'.\")\n",
    "\n",
    "  if choice == \"y\":\n",
    "    # Import libraries for plotting (replace with your preferred library)\n",
    "    try:\n",
    "      import matplotlib.pyplot as plt\n",
    "    except ModuleNotFoundError as e:\n",
    "      print(f\"\\n** Required library (matplotlib) not found for plotting. Skipping ROC curve.**\")\n",
    "      return\n",
    "\n",
    "    # Extract features and target\n",
    "    X_val = val_data.drop(\"target\", axis=1)\n",
    "    y_val = val_data[\"target\"]\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_pred_proba = trained_model.predict_proba(X_val)[:, 1]  # Assuming positive class probability\n",
    "\n",
    "    # Calculate ROC curve metrics\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "  else:\n",
    "    print(\"\\n** Skipping ROC curve visualization.**\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation of the Function:**\n",
    "\n",
    "1. **Function Purpose:** This function takes the trained model (`trained_model`) and validation data (`val_data`) as input, guiding the user through plotting ROC curves (applicable only for classification models).\n",
    "2. **Explanation of ROC Curves:** It informs the user about ROC curves and their purpose in understanding the trade-off between true and false positive rates.\n",
    "3. **Model Check:** It checks if the trained model has a `predict_proba` method, indicating probability prediction capabilities (essential for ROC curves).\n",
    "   - If not, it informs the user and skips ROC curve generation.\n",
    "4. **Confirmation for Plotting (if applicable):** It asks for user confirmation (y/n) to visualize ROC curves (only if the model can predict probabilities).\n",
    "5. **ROC Curve Plotting (if chosen - classification model):**\n",
    "   - It checks for `matplotlib` and informs the user if missing.\n",
    "   - If available, it extracts features and target from the validation data.\n",
    "   - It assumes the positive class probability is the second column (index 1) in the predicted probabilities.\n",
    "   - It calculates ROC curve metrics using `roc_curve` and `auc` from `sklearn.metrics`.\n",
    "   - The function plots the ROC curve using `matplotlib`, displaying the ROC AUC value.\n",
    "6. **Skipping Plotting (if not chosen or not a classification model):** Informs the user that ROC curve plotting is skipped.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Precision-Recall Curves (for Classification)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def plot_precision_recall_curve(trained_model, val_data):\n",
    "  \"\"\"\n",
    "  Guides the user through plotting precision-recall curves for the trained classification model.\n",
    "\n",
    "  Args:\n",
    "      trained_model (object): The trained classification model.\n",
    "      val_data (pandas.DataFrame): The DataFrame containing the validation data (features and target).\n",
    "  \"\"\"\n",
    "\n",
    "  print(\"\\n** Visualizing precision-recall curves (for classification models only)...**\")\n",
    "  print(\"Precision-recall curves show the trade-off between precision (minimizing false positives) and recall (minimizing false negatives) at different classification thresholds.\")\n",
    "\n",
    "  # Check if the model is a classification model\n",
    "  if not hasattr(trained_model, \"predict_proba\"):\n",
    "    print(\"\\n** This function is only applicable for classification models with probability prediction capabilities (predict_proba). Skipping precision-recall curve.**\")\n",
    "    return\n",
    "\n",
    "  # Confirmation for Precision-Recall Curve Plot\n",
    "  print(\"\\n** Would you like to visualize precision-recall curves? (y/n) **\")\n",
    "  while True:\n",
    "    choice = input().lower()\n",
    "    if choice in [\"y\", \"n\"]:\n",
    "      break\n",
    "    else:\n",
    "      print(\"Invalid choice. Please choose 'y' or 'n'.\")\n",
    "\n",
    "  if choice == \"y\":\n",
    "    # Import libraries for plotting (replace with your preferred library)\n",
    "    try:\n",
    "      import matplotlib.pyplot as plt\n",
    "    except ModuleNotFoundError as e:\n",
    "      print(f\"\\n** Required library (matplotlib) not found for plotting. Skipping precision-recall curve.**\")\n",
    "      return\n",
    "\n",
    "    # Extract features and target\n",
    "    X_val = val_data.drop(\"target\", axis=1)\n",
    "    y_val = val_data[\"target\"]\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_pred_proba = trained_model.predict_proba(X_val)[:, 1]  # Assuming positive class probability\n",
    "\n",
    "    # Calculate precision-recall curve metrics\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, y_pred_proba)\n",
    "\n",
    "    # Plot the precision-recall curve\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, label='Precision-Recall Curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "  else:\n",
    "    print(\"\\n** Skipping precision-recall curve visualization.**\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Function Purpose:** This function takes the trained model (`trained_model`) and validation data (`val_data`) as input, guiding the user through plotting precision-recall curves (applicable only for classification models).\n",
    "2. **Explanation of Precision-Recall Curves:** It informs the user about precision-recall curves and their purpose in understanding the trade-off between precision and recall.\n",
    "3. **Model Check:** It checks if the trained model has a `predict_proba` method, indicating probability prediction capabilities (essential for precision-recall curves).\n",
    "   - If not, it informs the user and skips precision-recall curve generation.\n",
    "4. **Confirmation for Plotting (if applicable):** It asks for user confirmation (y/n) to visualize precision-recall curves (only if the model can predict probabilities).\n",
    "5. **Precision-Recall Curve Plotting (if chosen - classification model):**\n",
    "   - It checks for `matplotlib` and informs the user if missing.\n",
    "   - If available, it extracts features and target from the validation data.\n",
    "   - It assumes the positive class probability is the second column (index 1) in the predicted probabilities.\n",
    "   - It calculates precision-recall curve metrics using `precision_recall_curve` from `sklearn.metrics`.\n",
    "   - The function plots the precision-recall curve using `matplotlib`.\n",
    "6. **Skipping Plotting (if not chosen or not a classification model):** Informs the user that precision-recall curve plotting is skipped.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SHAP Explanations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import shap  # Import shap library (assuming it's installed)\n",
    "except ModuleNotFoundError:\n",
    "  SHAP_AVAILABLE = False\n",
    "else:\n",
    "  SHAP_AVAILABLE = True\n",
    "\n",
    "def explain_with_shap(trained_model, val_data, explainer_type=\"force_plot\"):\n",
    "  \"\"\"\n",
    "  Guides the user through generating SHAP explanations for the trained model (if shap library is available).\n",
    "\n",
    "  Args:\n",
    "      trained_model (object): The trained model (any model supported by shap).\n",
    "      val_data (pandas.DataFrame): The DataFrame containing the validation data (features and target).\n",
    "      explainer_type (str, optional): The type of SHAP explainer to use (e.g., \"force_plot\", \"tree_explainer\"). Defaults to \"force_plot\".\n",
    "  \"\"\"\n",
    "\n",
    "  if not SHAP_AVAILABLE:\n",
    "    print(\"\\n** SHAP library not found. SHAP explanations are unavailable.**\")\n",
    "    return\n",
    "\n",
    "  print(\"\\n** Generating SHAP explanations (may take some time)...**\")\n",
    "  print(\"SHAP explains how each feature contributes to a model's prediction for a specific data point.\")\n",
    "\n",
    "  # Confirmation for SHAP Explanations\n",
    "  print(\"\\n** Would you like to generate SHAP explanations? (y/n) **\")\n",
    "  while True:\n",
    "    choice = input().lower()\n",
    "    if choice in [\"y\", \"n\"]:\n",
    "      break\n",
    "    else:\n",
    "      print(\"Invalid choice. Please choose 'y' or 'n'.\")\n",
    "\n",
    "  if choice == \"y\":\n",
    "    # Extract features and a single data point for explanation (can be modified to explain multiple points)\n",
    "    X_val = val_data.drop(\"target\", axis=1)\n",
    "    # Choose a data point for explanation (e.g., first row)\n",
    "    instance = X_val.iloc[0].values.reshape(1, -1)  # Reshape for single instance\n",
    "\n",
    "    # Create a SHAP explainer (consider different explainers based on model type)\n",
    "    if explainer_type == \"force_plot\":\n",
    "      explainer = shap.Explainer(trained_model.predict, instance)  # Force plot explainer\n",
    "    elif explainer_type == \"tree_explainer\" and hasattr(trained_model, \"tree_\"):\n",
    "      explainer = shap.TreeExplainer(trained_model)  # Tree explainer for tree-based models (if applicable)\n",
    "    else:\n",
    "      print(f\"\\n** Unsupported explainer type: {explainer_type}. Using force_plot explainer.\")\n",
    "      explainer = shap.Explainer(trained_model.predict, instance)  # Fallback to force plot\n",
    "\n",
    "    # Generate SHAP explanation\n",
    "    shap_values = explainer(instance)\n",
    "\n",
    "    # Display SHAP explanation (using shap library functions)\n",
    "    try:\n",
    "      shap.force_plot(explainer.base_value, instance, shap_values, feature_names=X_val.columns)  # Force plot for any model\n",
    "    except:\n",
    "      if explainer_type == \"tree_explainer\":\n",
    "        shap.summary_plot(shap_values, instance, feature_names=X_val.columns)  # Tree explainer summary plot (if applicable)\n",
    "      else:\n",
    "        print(\"\\n** Unable to display SHAP explanation using the chosen explainer type. Try 'force_plot'.\")\n",
    "\n",
    "  else:\n",
    "    print(\"\\n** Skipping SHAP explanations.**\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **SHAP Library Check:** It checks if the `shap` library is available. If not, it informs the user and skips the function.\n",
    "2. **Function Purpose:** This function takes the trained model (`trained_model`), validation data (`val_data`), and an optional explainer type (`explainer_type`) as input, guiding the user through generating SHAP explanations (if `shap` is available).\n",
    "3. **Explanation of SHAP:** It informs the user about the purpose of SHAP in understanding feature contributions to model predictions.\n",
    "4. **Confirmation for SHAP Explanations:** It asks for user confirmation (y/n) to generate explanations.\n",
    "5. **SHAP Explanations (if chosen):** \n",
    "   - It creates a SHAP explainer based on the chosen explainer type (`explainer_type`).\n",
    "     - It supports \"force_plot\" for any model type.\n",
    "     - It attempts to use \"tree_explainer\" for tree-based models if the model has a `tree_` attribute.\n",
    "     - If the explainer type is unsupported, it defaults to \"force_plot\" and informs the user.\n",
    "   - It generates SHAP values for the chosen data point using the explainer.\n",
    "   - It attempts to display the SHAP explanation using the `shap` library functions:\n",
    "     - For any model type with a force plot explainer, it displays a force plot using `shap.force_plot`.\n",
    "     - If the explainer type is \"tree_explainer\" and applicable, it displays a tree explainer summary plot using `shap.summary_plot`.\n",
    "     - If displaying fails, it informs the user and suggests using \"force_plot\".\n",
    "\n",
    "6. **Skipping SHAP Explanations (if not chosen):** Informs the user that SHAP explanations are skipped.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Partial Dependence Plots (PDPs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import partial_dependence\n",
    "\n",
    "def plot_partial_dependence(trained_model, val_data, feature_names=None):\n",
    "  \"\"\"\n",
    "  Guides the user through generating and visualizing partial dependence plots (PDPs) for the trained model.\n",
    "\n",
    "  Args:\n",
    "      trained_model (object): The trained model (any model supported by sklearn.inspection.partial_dependence).\n",
    "      val_data (pandas.DataFrame): The DataFrame containing the validation data (features and target).\n",
    "      feature_names (list, optional): The list of feature names (in the same order as the data). Defaults to None.\n",
    "  \"\"\"\n",
    "\n",
    "  print(\"\\n** Visualizing partial dependence plots (PDPs)...**\")\n",
    "  print(\"PDPs show the average effect of a single feature on the model's prediction, marginalizing over other features.\")\n",
    "\n",
    "  # Confirmation for PDP Visualization\n",
    "  print(\"\\n** Would you like to visualize PDPs? (y/n) **\")\n",
    "  while True:\n",
    "    choice = input().lower()\n",
    "    if choice in [\"y\", \"n\"]:\n",
    "      break\n",
    "    else:\n",
    "      print(\"Invalid choice. Please choose 'y' or 'n'.\")\n",
    "\n",
    "  if choice == \"y\":\n",
    "    # Extract features and target\n",
    "    X_val = val_data.drop(\"target\", axis=1)\n",
    "    y_val = val_data[\"target\"]\n",
    "\n",
    "    # Get feature names if not provided\n",
    "    if feature_names is None:\n",
    "      feature_names = X_val.columns.tolist()\n",
    "\n",
    "    # Choose a feature for PDP (can be modified to plot multiple features)\n",
    "    print(\"\\n** Select a feature to visualize its PDP: \")\n",
    "    for i, feature_name in enumerate(feature_names):\n",
    "      print(f\"{i+1}. {feature_name}\")\n",
    "    while True:\n",
    "      try:\n",
    "        feature_index = int(input()) - 1\n",
    "        if 0 <= feature_index < len(feature_names):\n",
    "          break\n",
    "        else:\n",
    "          print(\"Invalid choice. Please choose a feature number between 1 and\", len(feature_names))\n",
    "      except ValueError:\n",
    "        print(\"Invalid input. Please enter a number.\")\n",
    "\n",
    "    # Calculate PDP using partial_dependence\n",
    "    pdp, residuals = partial_dependence(trained_model, X_val, features=[feature_index])\n",
    "\n",
    "    # Plot the PDP\n",
    "    try:\n",
    "      import matplotlib.pyplot as plt\n",
    "      plt.figure()\n",
    "      plt.plot(X_val.iloc[:, feature_index], pdp.ravel(), label=feature_names[feature_index])  # Assuming single feature\n",
    "      plt.xlabel(feature_names[feature_index])\n",
    "      plt.ylabel(\"Average Prediction\")\n",
    "      plt.title(\"Partial Dependence Plot\")\n",
    "      plt.legend()\n",
    "      plt.grid(True)\n",
    "      plt.show()\n",
    "    except ModuleNotFoundError as e:\n",
    "      print(f\"\\n** Required library (matplotlib) not found for plotting. Skipping PDP.**\")\n",
    "      return\n",
    "\n",
    "  else:\n",
    "    print(\"\\n** Skipping partial dependence plot visualization.**\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Function Purpose:** This function takes the trained model (`trained_model`), validation data (`val_data`), and an optional list of feature names (`feature_names`) as input, guiding the user through generating and visualizing PDPs.\n",
    "2. **Explanation of PDPs:** It informs the user about PDPs and their purpose in understanding the effect of individual features on the model's prediction.\n",
    "3. **Confirmation for PDP Visualization:** It asks for user confirmation (y/n) to visualize PDPs.\n",
    "4. **PDP Visualization (if chosen):**\n",
    "   - It extracts features and target from the validation data.\n",
    "   - It retrieves feature names if not provided.\n",
    "   - It asks the user to choose a feature for the PDP plot.\n",
    "   - It calculates the PDP using `partial_dependence` from `sklearn.inspection`.\n",
    "   - The function plots the PDP using `matplotlib`, displaying the average prediction for different feature values.\n",
    "5. **Skipping PDP Visualization (if not chosen):** Informs the user that PDP visualization is skipped.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Importance Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def analyze_feature_importance(trained_model, val_data, feature_names=None):\n",
    "  \"\"\"\n",
    "  Guides the user through analyzing feature importance for the trained model.\n",
    "\n",
    "  Args:\n",
    "      trained_model (object): The trained model (any model supported by sklearn.inspection.permutation_importance).\n",
    "      val_data (pandas.DataFrame): The DataFrame containing the validation data (features and target).\n",
    "      feature_names (list, optional): The list of feature names (in the same order as the data). Defaults to None.\n",
    "  \"\"\"\n",
    "\n",
    "  print(\"\\n** Analyzing feature importance...**\")\n",
    "  print(\"Feature importance helps identify features that have a greater impact on the model's predictions.\")\n",
    "\n",
    "  # Confirmation for Feature Importance Analysis\n",
    "  print(\"\\n** Would you like to analyze feature importance? (y/n) **\")\n",
    "  while True:\n",
    "    choice = input().lower()\n",
    "    if choice in [\"y\", \"n\"]:\n",
    "      break\n",
    "    else:\n",
    "      print(\"Invalid choice. Please choose 'y' or 'n'.\")\n",
    "\n",
    "  if choice == \"y\":\n",
    "    # Extract features and target\n",
    "    X_val = val_data.drop(\"target\", axis=1)\n",
    "    y_val = val_data[\"target\"]\n",
    "\n",
    "    # Get feature names if not provided\n",
    "    if feature_names is None:\n",
    "      feature_names = X_val.columns.tolist()\n",
    "\n",
    "    # Calculate feature importance using permutation_importance\n",
    "    results = permutation_importance(trained_model, X_val, y_val, scoring=\"accuracy\")  # Replace 'accuracy' with relevant metric\n",
    "\n",
    "    # Print feature importances (sorted by importance)\n",
    "    feature_importances = results.importances_mean\n",
    "    feature_importances_sorted = sorted(zip(feature_names, feature_importances), key=lambda x: x[1], reverse=True)\n",
    "    print(\"\\n** Feature Importance Ranking: **\")\n",
    "    for i, (feature_name, importance) in enumerate(feature_importances_sorted):\n",
    "      print(f\"{i+1}. {feature_name}: {importance:.4f}\")\n",
    "\n",
    "  else:\n",
    "    print(\"\\n** Skipping feature importance analysis.**\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Persistence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(trained_model, save_path):\n",
    "  \"\"\"\n",
    "  Guides the user through saving the trained model.\n",
    "\n",
    "  Args:\n",
    "      trained_model (object): The trained model to save.\n",
    "      save_path (str): The path (including filename) to save the model.\n",
    "  \"\"\"\n",
    "\n",
    "  print(\"\\n** Saving the trained model (optional)...**\")\n",
    "  print(\"This allows you to use the trained model for future predictions without retraining.\")\n",
    "\n",
    "  # Confirmation for Model Persistence\n",
    "  print(\"\\n** Would you like to save the trained model? (y/n) **\")\n",
    "  while True:\n",
    "    choice = input().lower()\n",
    "    if choice in [\"y\", \"n\"]:\n",
    "      break\n",
    "    else:\n",
    "      print(\"Invalid choice. Please choose 'y' or 'n'.\")\n",
    "\n",
    "  if choice == \"y\":\n",
    "    try:\n",
    "      # Save the model using pickle\n",
    "      with open(save_path, 'wb') as f:\n",
    "        pickle.dump(trained_model, f)\n",
    "      print(f\"\\n** Model saved successfully to: {save_path}**\")\n",
    "    except Exception as e:\n",
    "      print(f\"\\n** Error saving the model: {e}**\")\n",
    "\n",
    "  else:\n",
    "    print(\"\\n** Skipping model persistence.**\")\n",
    "\n",
    "# Example usage \n",
    "save_model(trained_model, \"my_saved_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Function Purpose:** This function takes the trained model (`trained_model`) and the desired save path (`save_path`) as input, guiding the user through saving the model for later use.\n",
    "2. **Explanation of Model Persistence:** It informs the user about the benefits of saving the trained model to avoid retraining for future predictions.\n",
    "3. **Confirmation for Model Persistence:** It asks for user confirmation (y/n) to save the model.\n",
    "4. **Model Persistence (if chosen):**\n",
    "   - It attempts to save the model using the `pickle` library.\n",
    "   - If successful, it informs the user about the save location.\n",
    "   - If errors occur during saving, it informs the user about the encountered error.\n",
    "5. **Skipping Model Persistence (if not chosen):** Informs the user that model saving is skipped.\n",
    "\n",
    "\n",
    "**Important Note:**\n",
    "\n",
    "While `pickle` is a common and convenient option for model persistence in Python, it's essential to be aware of its limitations:\n",
    "\n",
    "* **Security:** Pickle can lead to security vulnerabilities if used with untrusted data. Make sure you only unpickle models from trusted sources.\n",
    "* **Compatibility:** Models saved with pickle might not be compatible with different Python versions or environments due to potential changes in libraries or model classes. Consider using more robust persistence formats like joblib (built on top of pickle) or PMML (Portable Model Markup Language) for better compatibility.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
